{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LMQL with OpenAI models\n",
    "Make sure to have followed the setup instructions in the `README.md` and that you have a `.env` file with your OpenAI API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "As of writing (20th of November, 2023), there are a few important limitations when using OpenAI models with LMQL. These limitations do not apply to local models.\n",
    "* Each placeholder causes a seperate call to the OpenAI API with the tokens up until the placeholder. This can result in excessive API usage.\n",
    "* Completion models (i.e. openai/gpt-3.5-turbo-instruct) support most of the functionality, although with some limitations (more details here: [LMQL - OpenAI API Limitations](https://lmql.ai/docs/models/openai.html#openai-api-limitations)).\n",
    "* Very limited support for Chat models (includes GPT4).\n",
    "\n",
    "View a list of supported models here: [LMQL - OpenAI](https://lmql.ai/docs/models/openai.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import lmql\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# View avilable models here: https://lmql.ai/docs/models/openai.html\n",
    "llm = 'openai/gpt-3.5-turbo-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query(model=llm)\n",
    "def capital_of_country(country):\n",
    "    '''lmql\n",
    "    \"What is the capital of {country}?\\n\"\n",
    "    \n",
    "    \"The capital of {country} is a nonsensical answer, and therefore you should [ANSWER]\" where STOPS_AT(ANSWER, \".\")\n",
    "    '''\n",
    "\n",
    "result = capital_of_country(\"Copenhagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of Copenhagen?\n",
      "The capital of Copenhagen is a nonsensical answer, and therefore you should not expect a valid response.\n"
     ]
    }
   ],
   "source": [
    "print(result.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ANSWER': 'Bucharest.'}\n"
     ]
    }
   ],
   "source": [
    "print(result.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor API usage\n",
    "You can monitor the API usage using the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmql.runtime.bopenai import get_stats\n",
    "print(get_stats())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lmql_demo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
